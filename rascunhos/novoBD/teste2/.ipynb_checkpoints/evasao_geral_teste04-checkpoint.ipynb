{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from doc_bd import Manage_db\n",
    "import json\n",
    "import os\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import re\n",
    "import urllib3 \n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "urllib3.disable_warnings()\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = Manage_db(database = 'lop2test', host = 'localhost', user='root', password='')\n",
    "\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client['lop2test']\n",
    "submissions_lop = db['submissions']\n",
    "\n",
    "#df_class.loc[df['id_class'] == 'f2dd7bef-5b5d-4cb3-9efa-aa8652af0605']\n",
    "id_class = 'e378c59f-e815-4a41-95fc-e95e4432a34c'\n",
    "#pd_data = pd.DataFrame([id_class], columns = ['id_class'])\n",
    "condition = \"WHERE class_id = 'e378c59f-e815-4a41-95fc-e95e4432a34c'\"\n",
    "df_submission = sql.search(table='submission')\n",
    "list_quest_subm = df_submission.drop(['ip', 'id', 'environment','hitPercentage','timeConsuming','createdAt','type','language', 'answer', 'char_change_number', 'user_id', 'lesson_id', 'class_id', 'test_id'], axis=1).drop_duplicates()\n",
    "df_submission_class = sql.search(table='submission', condition=condition)\n",
    "df_lop_lists = sql.search(table='listQuestions')\n",
    "\n",
    "df_lop_tests = sql.search(table='test')\n",
    "\n",
    "df_class = sql.search(table='class')\n",
    "df_quest = sql.search(table='question')\n",
    "\n",
    "users_class = sql.search(table='classHasUser')\n",
    "tag = sql.search(table='tag')\n",
    "quest_tag = sql.search(table='questionHasTag')\n",
    "df_list_q = sql.search(table='listHasQuestion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag.columns.values[0] ='tag_id'\n",
    "list_class = df_submission_class['listQuestions_id'].drop_duplicates().reset_index(name='id')\n",
    "a = df_lop_lists.columns.tolist()\n",
    "df_list_class = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(list_class.count().values[0]):\n",
    "    for a in range(df_lop_lists.count().values[0]):\n",
    "        if list_class['id'][i] == df_lop_lists['id'][a]:\n",
    "            b = dict(df_lop_lists.loc[a])\n",
    "            df_list_class = df_list_class.append(b, ignore_index=True)\n",
    "df_list_class.columns.values[0] = 'listQuestions_id'\n",
    "\n",
    "test_class = df_submission_class['test_id'].drop_duplicates().reset_index(name='id')\n",
    "a = df_lop_tests.columns.tolist()\n",
    "df_test_class = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(test_class.count().values[0]):\n",
    "    for a in range(df_lop_tests.count().values[0]):\n",
    "        if test_class['id'][i] == df_lop_tests['id'][a]:\n",
    "            b = dict(df_lop_tests.loc[a])\n",
    "            df_test_class = df_test_class.append(b, ignore_index=True)\n",
    "df_test_class.columns.values[0] = 'test_id'\n",
    "\n",
    "quest_class = df_submission_class['question_id'].drop_duplicates().reset_index(name='id')\n",
    "a = df_quest.columns.tolist()\n",
    "df_quest_class = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(quest_class.count().values[0]):\n",
    "    for a in range(df_quest.count().values[0]):\n",
    "        if quest_class['id'][i] == df_quest['id'][a]:\n",
    "            b = dict(df_quest.loc[a])\n",
    "            df_quest_class = df_quest_class.append(b, ignore_index=True)\n",
    "df_quest_class.columns.values[0] = 'question_id'\n",
    "\n",
    "#verificando o total de questoes cadastrados em listas da turma \n",
    "list_name = df_list_class['listQuestions_id'].tolist()\n",
    "a = df_list_q.columns.tolist()\n",
    "df_q_l = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(df_list_class.count().values[0]):\n",
    "    for a in range(df_list_q.count().values[0]):\n",
    "        if df_list_class['listQuestions_id'][i] == df_list_q['list_id'][a]:\n",
    "            b = dict(df_list_q.loc[a])\n",
    "            df_q_l = df_q_l.append(b, ignore_index=True)\n",
    "\n",
    "subs =[]\n",
    "for x in submissions_lop.find():\n",
    "    subs.append(x)\n",
    "df_class_lop = pd.DataFrame(subs)\n",
    "\n",
    "list_class = df_class_lop['listQuestions_id'].drop_duplicates().reset_index(name='id')\n",
    "a = df_lop_lists.columns.tolist()\n",
    "df_list_lop = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(list_class.count().values[0]):\n",
    "    for a in range(df_lop_lists.count().values[0]):\n",
    "        if list_class['id'][i] == df_lop_lists['id'][a]:\n",
    "            b = dict(df_lop_lists.loc[a])\n",
    "            df_list_lop = df_list_lop.append(b, ignore_index=True)\n",
    "df_list_lop.columns.values[0] = 'listQuestions_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aprovados - acima da media\n",
    "#submissoes da turma\n",
    "\n",
    "#retirando da df_class_lop todas as turmas do 2020.1\n",
    "l_classes = df_class_lop['class_id'].drop_duplicates().tolist()\n",
    "nclasses = []\n",
    "nclasses.append(l_classes[0])\n",
    "nclasses.append(l_classes[5])\n",
    "nclasses.append(l_classes[8])\n",
    "\n",
    "df_class_lop = df_class_lop.drop( df_class_lop[df_class_lop['class_id']==nclasses[0]].index )\n",
    "df_class_lop = df_class_lop.drop( df_class_lop[df_class_lop['class_id']==nclasses[1]].index )\n",
    "df_class_lop = df_class_lop.drop( df_class_lop[df_class_lop['class_id']==nclasses[2]].index )\n",
    "\n",
    "df_performance = df_class_lop.groupby(['class_id', 'user_id', 'listQuestions_id','question_id'])['hitPercentage'].max().reset_index()\n",
    "#soma das notas por lista\n",
    "df_performance = df_performance.groupby(['class_id', 'user_id','listQuestions_id'])['hitPercentage'].sum().reset_index()\n",
    "#Me traz as porcentagens maximas de acerto por questão\n",
    "df_performance = df_class_lop.groupby(['class_id', 'user_id','listQuestions_id','question_id'])['hitPercentage'].max().reset_index()\n",
    "      #Soma as porcentagens de uma lista/prova unica\n",
    "df_performance = df_performance.groupby(['class_id', 'user_id','listQuestions_id'])['hitPercentage'].sum().reset_index()\n",
    "      #Renomeando para melhorar entendimento\n",
    "df_performance.rename(columns={'hitPercentage':'totalHitPercentage'}, inplace = True)\n",
    "#Listas cadastradas nessa turma\n",
    "lists = df_class_lop['listQuestions_id'].drop_duplicates().values\n",
    "#Lista de alunos\n",
    "df_without_duplicates = df_class_lop.drop_duplicates(subset=['class_id', 'user_id'])\n",
    "\n",
    "df_prov = pd.DataFrame()\n",
    "for lista in lists:\n",
    "    df_users = df_without_duplicates.copy()\n",
    "    df_users['listQuestions_id'] = lista\n",
    "    df_prov = df_prov.append(df_users)\n",
    "\n",
    "df_performance = pd.merge(df_performance,df_prov, on=['class_id', 'user_id','listQuestions_id'], how='outer')#.fillna(0)  \n",
    "      #Conta quantas questões tem por lista\n",
    "df_question_data = list_quest_subm.groupby(['listQuestions_id'])['question_id'].count().reset_index(name='totalQuestionslist')\n",
    "      #Merge\n",
    "df_performance = df_performance.merge(df_question_data, on = 'listQuestions_id')\n",
    "    #Média de acerto por lista\n",
    "df_performance['medialist'] = df_performance['totalHitPercentage'] / df_performance['totalQuestionslist']\n",
    "      #Convertendo para datetime\n",
    "df_lop_lists['createdAt'] = pd.to_datetime(df_lop_lists['createdAt'])\n",
    "      #Criando campo com a data\n",
    "df_lop_lists['dateList'] = df_lop_lists['createdAt'].dt.date\n",
    "      #Merge\n",
    "lists_df = df_list_lop\n",
    "lists_df.columns.values[0] = 'listQuestions_id'\n",
    "\n",
    "df_performance = pd.merge(df_performance, lists_df.drop(columns = ['createdAt']), on='listQuestions_id')\n",
    "    #graph1\n",
    "    #Número de alunos na turma\n",
    "    #Media por lista por cada turma\n",
    "newDf = df_performance\n",
    "newDf = newDf.groupby(['user_id', 'class_id'])['medialist'].sum().reset_index()\n",
    "newDf['medialist'] = newDf['medialist'] / lists_df.count().values[0]\n",
    "\n",
    "newDf['aprovado'] = 2\n",
    "for a in range(newDf.count().values[0]):\n",
    "    if newDf['medialist'].values[a]>=50:\n",
    "        newDf['aprovado'][a]=1\n",
    "    else:\n",
    "        newDf['aprovado'][a]=0\n",
    "        \n",
    "df_class_lop_t = df_class_lop.sort_values('createdAt')\n",
    "classes = df_class_lop_t['class_id'].drop_duplicates().tolist()\n",
    "\n",
    "order_lists = pd.DataFrame(columns = ['class_id', 'listQuestions_id'])\n",
    "for i in range(len(classes)):\n",
    "    one_class = df_class_lop_t[df_class_lop_t['class_id']==classes[i]]\n",
    "    order_lists0 = one_class['listQuestions_id'].drop_duplicates().tolist()\n",
    "    for a in range(len(order_lists0)):\n",
    "        b = dict({'class_id':classes[i], 'listQuestions_id':order_lists0[a]})\n",
    "        order_lists = order_lists.append(b, ignore_index=True)\n",
    "#oberservar a ordem de saída de cada user para não ter problemas posteriores, \n",
    "#por conta da ordem de inserção do 'ateLista' para cada aluno\n",
    "usersp = df_class_lop_t.drop_duplicates(subset=['class_id', 'user_id']).drop(['_id','id','ip','type', 'environment', 'hitPercentage','timeConsuming','createdAt','language', 'answer', 'char_change_number', 'lesson_id','test_id', 'question_id', 'listQuestions_id'], axis=1)\n",
    "usersp['ateLista'] = 0\n",
    "\n",
    "one_class = df_class_lop_t[df_class_lop_t['class_id']==classes[0]]\n",
    "users = one_class['user_id'].drop_duplicates().tolist()\n",
    "\n",
    "alunoPclass = pd.DataFrame(columns = ['class_id', 'qtd_user'])\n",
    "for x in range(len(classes)):\n",
    "    teste = df_class_lop_t[df_class_lop_t['class_id']==classes[x]]\n",
    "    teste = teste['user_id'].drop_duplicates()\n",
    "    teste = teste.count()\n",
    "    b = dict({'class_id':classes[x], 'qtd_user':teste})\n",
    "    alunoPclass = alunoPclass.append(b, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_ate = []\n",
    "cont = 0\n",
    "a = usersp.columns.tolist()\n",
    "newTeste = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(alunoPclass.count().values[0]):\n",
    "    one_class = df_class_lop_t[df_class_lop_t['class_id']==classes[i]]\n",
    "    users = one_class['user_id'].drop_duplicates().tolist()\n",
    "    for y in range(alunoPclass['qtd_user'][i]):\n",
    "        one_studt = one_class[one_class['user_id']==users[y]]\n",
    "        qtd_ate_l0 = one_studt['listQuestions_id'].drop_duplicates().tolist()\n",
    "        maior = 0\n",
    "        for x in range(len(qtd_ate_l0)):\n",
    "            order_lists1 = order_lists[order_lists['class_id']==classes[i]]\n",
    "            order_lists1 = order_lists1['listQuestions_id'].tolist()\n",
    "            cont=cont+1\n",
    "            for z in range(len(order_lists1)):\n",
    "                if qtd_ate_l0[x] == order_lists1[z]:\n",
    "                    if maior < z:\n",
    "                        maior = z\n",
    "        if(users[y]=='fe3c3b36-a1ab-4365-b088-1686cd5177d0'):\n",
    "            print(maior)\n",
    "            print(cont)\n",
    "        b = dict({'class_id':classes[i], 'user_id':users[y], 'ateLista':maior})\n",
    "        newTeste = newTeste.append(b, ignore_index=True)\n",
    "usersp = newTeste.copy()\n",
    "\n",
    "#para verificar por turma\n",
    "#qtd_ateLista = usersp.groupby(['ateLista', 'class_id'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "qtd_ateLista = usersp.groupby(['ateLista'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "qtd_totalAteLista = qtd_ateLista\n",
    "for x in range(len(qtd_totalAteLista)):\n",
    "    qtd_totalAteLista['totalDeAlunosAteLista'][x+1]= qtd_totalAteLista['totalDeAlunosAteLista'][x] + qtd_totalAteLista['totalDeAlunosAteLista'][x+1]\n",
    "    if x==len(qtd_totalAteLista)-2:\n",
    "        break\n",
    "usersAteApr = pd.merge(newDf,usersp, on=['user_id', 'class_id'], how='outer')\n",
    "#erro\n",
    "aprovs = usersAteApr[usersAteApr['aprovado']==1]\n",
    "aprAlista = aprovs.groupby(['ateLista'])['aprovado'].count().reset_index(name='totalDeAprAteLista')\n",
    "ate_Lista = usersp.groupby(['ateLista'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "porcentAtePlista = usersp.groupby(['ateLista'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "porcentAtePlista['totalDeAlunosAteLista']=0.0\n",
    "for x in range(len(ate_Lista)):\n",
    "    for a in range(len(aprAlista)):\n",
    "        if ate_Lista['ateLista'][x] == aprAlista['ateLista'][a]:\n",
    "            porcentAtePlista['totalDeAlunosAteLista'][x] = aprAlista['totalDeAprAteLista'][a] / ate_Lista['totalDeAlunosAteLista'][x]\n",
    "#salvando todas as submissoes em ordem temporal\n",
    "df_class_lop_t = df_class_lop.sort_values('createdAt')\n",
    "#salavndo a quantidade de listas que cada aluno resolveu\n",
    "usersQtd = df_class_lop_t.groupby(['user_id','listQuestions_id', 'class_id'])['question_id'].count().reset_index(name='qtdLista')\n",
    "usersQtd = usersQtd.groupby(['user_id', 'class_id'])['listQuestions_id'].count().reset_index(name='qtdLista')\n",
    "qtd_Lista = usersQtd.groupby(['qtdLista'])['user_id'].count().reset_index(name='totalDeAlunosQtdLista')\n",
    "porc_qtd_Lista = usersQtd.groupby(['qtdLista'])['user_id'].count().reset_index(name='totalDeAlunosQtdLista')\n",
    "for a in range(len(qtd_Lista)):\n",
    "    atual = usersQtd[usersQtd['qtdLista']==a+1]\n",
    "    cont=0\n",
    "    total=atual.count().values[0]\n",
    "    for x in range(total):\n",
    "        verif_user=newDf[newDf['user_id']==atual['user_id'].iloc[x]]\n",
    "        if verif_user['aprovado'].values[0]==1:\n",
    "            cont=cont+1\n",
    "usersQtdApr = pd.merge(newDf,usersQtd, on=['user_id', 'class_id'], how='outer')\n",
    "aprovs = usersQtdApr[usersQtdApr['aprovado']==1]\n",
    "aprPlista = aprovs.groupby(['qtdLista'])['aprovado'].count().reset_index(name='totalDeAprQtdLista')\n",
    "qtd_Lista = usersQtd.groupby(['qtdLista'])['user_id'].count().reset_index(name='totalDeAlunosQtdLista')\n",
    "porcentAprPlista = usersQtd.groupby(['qtdLista'])['user_id'].count().reset_index(name='totalDeAlunosQtdLista')\n",
    "porcentAprPlista['totalDeAlunosQtdLista']=0.0\n",
    "for x in range(len(qtd_Lista)):\n",
    "    for a in range(len(aprPlista)):\n",
    "        if qtd_Lista['qtdLista'][x] == aprPlista['qtdLista'][a]:\n",
    "#            print(x)\n",
    "            porcentAprPlista['totalDeAlunosQtdLista'][x] = aprPlista['totalDeAprQtdLista'][a] / qtd_Lista['totalDeAlunosQtdLista'][x]\n",
    "qtd_ateLista = usersp.groupby(['ateLista'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "\n",
    "usersQtdApr2 = pd.merge(newDf,usersp, on=['user_id','class_id'], how='outer')\n",
    "qtd_ate = pd.merge(usersQtd,usersp, on=['user_id','class_id'], how='outer')\n",
    "usersQtdAte = pd.merge(newDf,qtd_ate, on=['user_id','class_id'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#contando o erro por questao acima do tempo zero para prevenir duplo clicke. geralmente, se há cola ou algum problema relacionado, acaba nao sendo um erro na questao\n",
    "#buscando erros por lista, por aluno\n",
    "df_class_lop_t['timeInSecounds'] = df_class_lop_t['timeConsuming'].divide(1000).astype(int)\n",
    "\n",
    "df_without_duplicates = df_class_lop_t[df_class_lop_t[\"timeInSecounds\"] > 0].drop(['language','test_id','environment','timeConsuming','createdAt','timeInSecounds','char_change_number', 'ip', 'type', 'answer', 'lesson_id', 'id'], axis=1)\n",
    "df_erro = df_without_duplicates[df_without_duplicates[\"hitPercentage\"] == 0]\n",
    "df_erro = df_erro.groupby(['user_id','class_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalError')\n",
    "df_erro = df_erro.groupby(['class_id','user_id'])['totalError'].sum()\n",
    "\n",
    "#buscando quantidade de questoes certas por lista por aluno\n",
    "df_acerto = df_without_duplicates[df_without_duplicates[\"hitPercentage\"] > 0]\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalAcert')\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id'])['totalAcert'].sum()\n",
    "\n",
    "#buscando quantidade de questoes que com 100% de acerto por lista por aluno\n",
    "df_100 = df_without_duplicates[df_without_duplicates[\"hitPercentage\"] == 100].drop_duplicates()\n",
    "df_100 = df_100.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='acert_100')\n",
    "df_100 = df_100.groupby(['class_id','user_id'])['acert_100'].sum()\n",
    "\n",
    "#buscar se o aluno chegou a tirar 100 na questão ou a nota final.\n",
    "#há mais de um acerto, pois há mais vezes que tentam tirar mais que zero, mas nem sempre chegam no 100\n",
    "#avaliar a possibilidade de colocar a nota maxima do aluno em coluna\n",
    "\n",
    "df = pd.merge(df_erro, df_acerto, on=['class_id','user_id'], how='outer')\n",
    "df = pd.merge(df, df_100, on=['class_id','user_id'], how='outer')\n",
    "df.replace(np.NaN, 0, inplace = True)\n",
    "df = pd.merge(df, newDf, on=['class_id','user_id']).drop('medialist', axis=1)\n",
    "\n",
    "a = df_without_duplicates.drop(['_id', 'hitPercentage', 'listQuestions_id'], axis=1).drop_duplicates()\n",
    "qtd_qPa = a.groupby(['class_id','user_id'])['question_id'].count().reset_index(name='totalQuest')\n",
    "media_df = pd.merge(df, qtd_qPa, on=['class_id','user_id'])\n",
    "media_df['totalError'] = media_df['totalError'] / media_df['totalQuest']\n",
    "media_df['totalAcert'] = media_df['totalAcert'] / media_df['totalQuest']\n",
    "media_df['acert_100'] = media_df['acert_100'] / media_df['totalQuest']\n",
    "df_cont_subm = df_without_duplicates.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='total_subm')\n",
    "df_cont_subm = df_cont_subm.groupby(['class_id','user_id'])['total_subm'].sum()\n",
    "media_df1 = pd.merge(df_cont_subm, qtd_qPa, on=['class_id','user_id'])\n",
    "media_df1['total_subm'] = media_df1['total_subm'] / media_df1['totalQuest']\n",
    "df_total = pd.merge(df_cont_subm, df, on=['class_id','user_id'])\n",
    "prob_total = pd.merge(df_cont_subm, df, on=['class_id','user_id'])\n",
    "prob_total['totalError'] = prob_total['totalError'] / prob_total['total_subm']\n",
    "prob_total['totalAcert'] = prob_total['totalAcert'] / prob_total['total_subm']\n",
    "prob_total['acert_100'] = prob_total['acert_100'] / prob_total['total_subm']\n",
    "#refazer o indice de desistencia, tendo em vista os índices já vistos \n",
    "des = usersp.copy()\n",
    "des['desistente'] = 2\n",
    "for a in range(des.count().values[0]):\n",
    "    if des['ateLista'].values[a]<4:\n",
    "        des['desistente'][a]=1\n",
    "    else:\n",
    "        des['desistente'][a]=0\n",
    "prob_total_des = pd.merge(des, prob_total, on=['class_id','user_id']).drop('aprovado', axis=1)\n",
    "df_cont_subm = df_without_duplicates.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='total_subm')\n",
    "df_cont_subm = df_cont_subm.groupby(['class_id','user_id'])['total_subm'].sum()\n",
    "\n",
    "a = df_without_duplicates.drop(['_id', 'hitPercentage', 'listQuestions_id'], axis=1).drop_duplicates()\n",
    "qtd_qPa = a.groupby(['class_id','user_id'])['question_id'].count().reset_index(name='totalQuest')\n",
    "\n",
    "media_des0 = pd.merge(df_cont_subm, qtd_qPa, on=['class_id','user_id'])\n",
    "media_des0['subm/quest'] = media_des0['total_subm'] / media_des0['totalQuest']\n",
    "media_des = pd.merge(media_des0, des, on=['class_id','user_id'])\n",
    "#prob_total_des\n",
    "ind = prob_total_des.copy()\n",
    "ind = ind.drop(['ateLista', 'total_subm'], axis=1)\n",
    "ind = pd.merge(ind, media_des0, on=['class_id', 'user_id'])\n",
    "ind['teste'] = ind['subm/quest'] * ind['totalAcert']\n",
    "test_des = ind[ind['desistente']==1]\n",
    "test_ndes = ind[ind['desistente']==0]\n",
    "\n",
    "newind = ind[ind['teste']<=test_des['teste'].max()]\n",
    "newind['teste2'] = ind['teste'] * ind['acert_100']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_lop_t['timeInSecounds'] = df_class_lop_t['timeConsuming'].divide(1000).astype(int)\n",
    "df_without_duplicates = df_class_lop_t[df_class_lop_t[\"timeInSecounds\"] > 0].drop(['language','test_id','environment','timeConsuming','char_change_number', 'ip', 'type', 'answer', 'lesson_id', 'id'], axis=1)\n",
    "\n",
    "a = df_without_duplicates.columns.tolist()\n",
    "list1 = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(alunoPclass.count().values[0]):\n",
    "    one_class = df_without_duplicates[df_without_duplicates['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists[order_lists['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists1['listQuestions_id'].tolist()\n",
    "    order_lists1 = order_lists1[0]\n",
    "    listeste = one_class[one_class['listQuestions_id']==order_lists1]\n",
    "    list1 = list1.append(listeste, ignore_index=True)\n",
    "\n",
    "a = df_without_duplicates.columns.tolist()\n",
    "list2 = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(alunoPclass.count().values[0]):\n",
    "    one_class = df_without_duplicates[df_without_duplicates['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists[order_lists['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists1['listQuestions_id'].tolist()\n",
    "    order_lists1 = order_lists1[1]\n",
    "    listeste = one_class[one_class['listQuestions_id']==order_lists1]\n",
    "    list2 = list2.append(listeste, ignore_index=True)\n",
    "\n",
    "a = df_without_duplicates.columns.tolist()\n",
    "list3 = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(alunoPclass.count().values[0]):\n",
    "    one_class = df_without_duplicates[df_without_duplicates['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists[order_lists['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists1['listQuestions_id'].tolist()\n",
    "    order_lists1 = order_lists1[2]\n",
    "    listeste = one_class[one_class['listQuestions_id']==order_lists1]\n",
    "    list3 = list3.append(listeste, ignore_index=True)\n",
    "list3\n",
    "\n",
    "a = df_without_duplicates.columns.tolist()\n",
    "list4 = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(alunoPclass.count().values[0]):\n",
    "    one_class = df_without_duplicates[df_without_duplicates['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists[order_lists['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists1['listQuestions_id'].tolist()\n",
    "    order_lists1 = order_lists1[3]\n",
    "    listeste = one_class[one_class['listQuestions_id']==order_lists1]\n",
    "    list4 = list4.append(listeste, ignore_index=True)\n",
    "list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_aqui = des.copy()\n",
    "\n",
    "tlist4 = list1.copy()\n",
    "tlist4 = tlist4.append(list2)\n",
    "tlist4 = tlist4.append(list3)\n",
    "tlist4 = tlist4.append(list4)\n",
    "tlist4 = tlist4.reset_index()\n",
    "\n",
    "a = des_aqui[ des_aqui['ateLista'] < 3]\n",
    "indexNames = []\n",
    "for i in a.values:\n",
    "    b = tlist4[tlist4['user_id'] == i[0]].index\n",
    "    for x in b:\n",
    "        indexNames.append(x)\n",
    "tlist4 = tlist4.drop(tlist4.index[indexNames])\n",
    "\n",
    "for a in range(des_aqui.count().values[0]):\n",
    "    if des_aqui['ateLista'].values[a]<4:\n",
    "        des_aqui['desistente'][a]=1\n",
    "    else:\n",
    "        des_aqui['desistente'][a]=0\n",
    "        \n",
    "a = des[ des['ateLista'] < 3]\n",
    "indexNames = []\n",
    "for i in a.values:\n",
    "    b = des_aqui[des_aqui['user_id'] == i[0]].index\n",
    "    for x in b:\n",
    "        indexNames.append(x)\n",
    "des_aqui = des_aqui.drop(des_aqui.index[indexNames])\n",
    "\n",
    "list4 = tlist4.copy()\n",
    "\n",
    "df_erro = list4[list4[\"hitPercentage\"] == 0]\n",
    "df_erro = df_erro.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalError')\n",
    "df_erro = df_erro.groupby(['class_id','user_id'])['totalError'].sum()\n",
    "\n",
    "#buscando quantidade de questoes certas por lista por aluno\n",
    "df_acerto = list4[list4[\"hitPercentage\"] > 0]\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalAcert')\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id'])['totalAcert'].sum()\n",
    "\n",
    "#buscando quantidade de questoes que com 100% de acerto por lista por aluno\n",
    "df_100 = list4[list4[\"hitPercentage\"] == 100].drop_duplicates()\n",
    "df_100 = df_100.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='acert_100')\n",
    "df_100 = df_100.groupby(['class_id','user_id'])['acert_100'].sum()\n",
    "\n",
    "df_cont_subm = list4.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='total_subm')\n",
    "df_cont_subm = df_cont_subm.groupby(['class_id','user_id'])['total_subm'].sum()\n",
    "\n",
    "a = list4.drop(['_id', 'hitPercentage', 'listQuestions_id','createdAt', 'timeInSecounds'], axis=1)\n",
    "a = a.drop('index', axis=1)\n",
    "a = a.drop_duplicates()\n",
    "qtd_qPa = a.groupby(['class_id','user_id'])['question_id'].count().reset_index(name='totalQuest')\n",
    "\n",
    "media_list1 = pd.merge(df_cont_subm, qtd_qPa, on=['class_id','user_id'])\n",
    "media_list1['subm/quest'] = media_list1['total_subm'] / media_list1['totalQuest']\n",
    "\n",
    "tempott = list4.groupby(['class_id','user_id'])['timeInSecounds'].sum()\n",
    "\n",
    "#buscar se o aluno chegou a tirar 100 na questão ou a nota final.\n",
    "#há mais de um acerto, pois há mais vezes que tentam tirar mais que zero, mas nem sempre chegam no 100\n",
    "#avaliar a possibilidade de colocar a nota maxima do aluno em coluna\n",
    "\n",
    "df_list4 = pd.merge(df_erro, df_acerto, on=['class_id','user_id'], how='outer')\n",
    "df_list4 = pd.merge(df_list4, df_100, on=['class_id','user_id'], how='outer')\n",
    "df_list4.replace(np.NaN, 0, inplace = True)\n",
    "df_list4 = pd.merge(df_list4, des_aqui, on=['class_id','user_id'])\n",
    "df_list4 = pd.merge(df_list4, media_list1, on=['class_id','user_id'])\n",
    "df_list4 = pd.merge(df_list4, tempott, on=['class_id','user_id'])\n",
    "#des_aqui[des_aqui['desistente']==1]\n",
    "#print(des_aqui[des_aqui['desistente']==1].count().values[0])\n",
    "df_list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list4['percTotalError'] = df_list4['totalError'] / df_list4['total_subm']\n",
    "df_list4['percTotalAcert'] = df_list4['totalAcert'] / df_list4['total_subm']\n",
    "df_list4['percAcert_100'] = df_list4['acert_100'] / df_list4['total_subm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list4[df_list4['desistente']==1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_desist = df_list4['desistente'].tolist()\n",
    "x_dados = df_list4.drop(['class_id', 'user_id', 'desistente', 'ateLista'], axis=1)\n",
    "x_dados = x_dados.values\n",
    "x_dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_dados, y_desist, test_size=0.3, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=1)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = df_list4.drop(['class_id', 'user_id', 'desistente', 'ateLista'], axis=1)\n",
    "bx = bx.columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 14))\n",
    "\n",
    "plot_tree(dt_model, filled=True, rounded=True,class_names=['Não desistente','Desistente',],feature_names=bx)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
