{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from doc_bd import Manage_db\n",
    "import json\n",
    "import os\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import re\n",
    "import urllib3 \n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "urllib3.disable_warnings()\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = Manage_db(database = 'lop2test', host = 'localhost', user='root', password='')\n",
    "\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client['lop2test']\n",
    "submissions_lop = db['submissions']\n",
    "\n",
    "#df_class.loc[df['id_class'] == 'f2dd7bef-5b5d-4cb3-9efa-aa8652af0605']\n",
    "id_class = 'e378c59f-e815-4a41-95fc-e95e4432a34c'\n",
    "#pd_data = pd.DataFrame([id_class], columns = ['id_class'])\n",
    "condition = \"WHERE class_id = 'e378c59f-e815-4a41-95fc-e95e4432a34c'\"\n",
    "df_submission = sql.search(table='submission')\n",
    "list_quest_subm = df_submission.drop(['ip', 'id', 'environment','hitPercentage','timeConsuming','createdAt','type','language', 'answer', 'char_change_number', 'user_id', 'lesson_id', 'class_id', 'test_id'], axis=1).drop_duplicates()\n",
    "df_submission_class = sql.search(table='submission', condition=condition)\n",
    "df_lop_lists = sql.search(table='listQuestions')\n",
    "\n",
    "df_lop_tests = sql.search(table='test')\n",
    "\n",
    "df_class = sql.search(table='class')\n",
    "df_quest = sql.search(table='question')\n",
    "\n",
    "users_class = sql.search(table='classHasUser')\n",
    "tag = sql.search(table='tag')\n",
    "quest_tag = sql.search(table='questionHasTag')\n",
    "df_list_q = sql.search(table='listHasQuestion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente, Timeout: 30s, Topology Description: <TopologyDescription id: 63068abf5d03322f2fa72691, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente')>]>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-206349cf251f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0msubs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubmissions_lop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0msubs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mdf_class_lop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymongo\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1238\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1239\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                 \u001b[0m_db\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymongo\\cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__session\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Query\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_ensure_session\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m   1933\u001b[0m             \u001b[1;31m# Don't make implicit sessions causally consistent. Applications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1934\u001b[0m             \u001b[1;31m# should always opt-in.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1935\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__start_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcausal_consistency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1936\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mConfigurationError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInvalidOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1937\u001b[0m             \u001b[1;31m# Sessions not supported, or multiple users authenticated.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m__start_session\u001b[1;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[0;32m   1881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[1;31m# Raises ConfigurationError if sessions are not supported.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0mserver_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_server_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSessionOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m         return client_session.ClientSession(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_get_server_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1919\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_server_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[1;34m\"\"\"Internal: start or resume a _ServerSession.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1921\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_topology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_server_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_return_server_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36mget_server_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[1;31m# Sessions are always supported in load balanced mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_balanced\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m                 \u001b[0msession_timeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_session_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m                 \u001b[1;31m# Sessions never time out in load balanced mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36m_check_session_support\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    500\u001b[0m                         \u001b[0many_server_selector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_selection_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m                         None)\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_description\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadable_servers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 self._select_servers_loop(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[1;34m(self, selector, timeout, address)\u001b[0m\n\u001b[0;32m    218\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[0;32m    219\u001b[0m                     \u001b[1;34m\"%s, Timeout: %ss, Topology Description: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                     (self._error_message(selector), timeout, self.description))\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_opened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente, Timeout: 30s, Topology Description: <TopologyDescription id: 63068abf5d03322f2fa72691, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente')>]>"
     ]
    }
   ],
   "source": [
    "tag.columns.values[0] ='tag_id'\n",
    "list_class = df_submission_class['listQuestions_id'].drop_duplicates().reset_index(name='id')\n",
    "a = df_lop_lists.columns.tolist()\n",
    "df_list_class = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(list_class.count().values[0]):\n",
    "    for a in range(df_lop_lists.count().values[0]):\n",
    "        if list_class['id'][i] == df_lop_lists['id'][a]:\n",
    "            b = dict(df_lop_lists.loc[a])\n",
    "            df_list_class = df_list_class.append(b, ignore_index=True)\n",
    "df_list_class.columns.values[0] = 'listQuestions_id'\n",
    "\n",
    "test_class = df_submission_class['test_id'].drop_duplicates().reset_index(name='id')\n",
    "a = df_lop_tests.columns.tolist()\n",
    "df_test_class = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(test_class.count().values[0]):\n",
    "    for a in range(df_lop_tests.count().values[0]):\n",
    "        if test_class['id'][i] == df_lop_tests['id'][a]:\n",
    "            b = dict(df_lop_tests.loc[a])\n",
    "            df_test_class = df_test_class.append(b, ignore_index=True)\n",
    "df_test_class.columns.values[0] = 'test_id'\n",
    "\n",
    "quest_class = df_submission_class['question_id'].drop_duplicates().reset_index(name='id')\n",
    "a = df_quest.columns.tolist()\n",
    "df_quest_class = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(quest_class.count().values[0]):\n",
    "    for a in range(df_quest.count().values[0]):\n",
    "        if quest_class['id'][i] == df_quest['id'][a]:\n",
    "            b = dict(df_quest.loc[a])\n",
    "            df_quest_class = df_quest_class.append(b, ignore_index=True)\n",
    "df_quest_class.columns.values[0] = 'question_id'\n",
    "\n",
    "#verificando o total de questoes cadastrados em listas da turma \n",
    "list_name = df_list_class['listQuestions_id'].tolist()\n",
    "a = df_list_q.columns.tolist()\n",
    "df_q_l = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(df_list_class.count().values[0]):\n",
    "    for a in range(df_list_q.count().values[0]):\n",
    "        if df_list_class['listQuestions_id'][i] == df_list_q['list_id'][a]:\n",
    "            b = dict(df_list_q.loc[a])\n",
    "            df_q_l = df_q_l.append(b, ignore_index=True)\n",
    "\n",
    "subs =[]\n",
    "for x in submissions_lop.find():\n",
    "    subs.append(x)\n",
    "df_class_lop = pd.DataFrame(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_class = df_class_lop['listQuestions_id'].drop_duplicates().reset_index(name='id')\n",
    "a = df_lop_lists.columns.tolist()\n",
    "df_list_lop = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(list_class.count().values[0]):\n",
    "    for a in range(df_lop_lists.count().values[0]):\n",
    "        if list_class['id'][i] == df_lop_lists['id'][a]:\n",
    "            b = dict(df_lop_lists.loc[a])\n",
    "            df_list_lop = df_list_lop.append(b, ignore_index=True)\n",
    "df_list_lop.columns.values[0] = 'listQuestions_id'\n",
    "df_list_lop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aprovados - acima da media\n",
    "#submissoes da turma\n",
    "\n",
    "#retirando da df_class_lop todas as turmas do 2020.1\n",
    "l_classes = df_class_lop['class_id'].drop_duplicates().tolist()\n",
    "nclasses = []\n",
    "nclasses.append(l_classes[0])\n",
    "nclasses.append(l_classes[5])\n",
    "nclasses.append(l_classes[8])\n",
    "\n",
    "df_class_lop = df_class_lop.drop( df_class_lop[df_class_lop['class_id']==nclasses[0]].index )\n",
    "df_class_lop = df_class_lop.drop( df_class_lop[df_class_lop['class_id']==nclasses[1]].index )\n",
    "df_class_lop = df_class_lop.drop( df_class_lop[df_class_lop['class_id']==nclasses[2]].index )\n",
    "\n",
    "df_performance = df_class_lop.groupby(['class_id', 'user_id', 'listQuestions_id','question_id'])['hitPercentage'].max().reset_index()\n",
    "#soma das notas por lista\n",
    "df_performance = df_performance.groupby(['class_id', 'user_id','listQuestions_id'])['hitPercentage'].sum().reset_index()\n",
    "#Me traz as porcentagens maximas de acerto por questão\n",
    "df_performance = df_class_lop.groupby(['class_id', 'user_id','listQuestions_id','question_id'])['hitPercentage'].max().reset_index()\n",
    "      #Soma as porcentagens de uma lista/prova unica\n",
    "df_performance = df_performance.groupby(['class_id', 'user_id','listQuestions_id'])['hitPercentage'].sum().reset_index()\n",
    "      #Renomeando para melhorar entendimento\n",
    "df_performance.rename(columns={'hitPercentage':'totalHitPercentage'}, inplace = True)\n",
    "#Listas cadastradas nessa turma\n",
    "lists = df_class_lop['listQuestions_id'].drop_duplicates().values\n",
    "#Lista de alunos\n",
    "df_without_duplicates = df_class_lop.drop_duplicates(subset=['class_id', 'user_id'])\n",
    "\n",
    "df_prov = pd.DataFrame()\n",
    "for lista in lists:\n",
    "    df_users = df_without_duplicates.copy()\n",
    "    df_users['listQuestions_id'] = lista\n",
    "    df_prov = df_prov.append(df_users)\n",
    "\n",
    "df_performance = pd.merge(df_performance,df_prov, on=['class_id', 'user_id','listQuestions_id'], how='outer')#.fillna(0)  \n",
    "      #Conta quantas questões tem por lista\n",
    "df_question_data = list_quest_subm.groupby(['listQuestions_id'])['question_id'].count().reset_index(name='totalQuestionslist')\n",
    "      #Merge\n",
    "df_performance = df_performance.merge(df_question_data, on = 'listQuestions_id')\n",
    "    #Média de acerto por lista\n",
    "df_performance['medialist'] = df_performance['totalHitPercentage'] / df_performance['totalQuestionslist']\n",
    "      #Convertendo para datetime\n",
    "df_lop_lists['createdAt'] = pd.to_datetime(df_lop_lists['createdAt'])\n",
    "      #Criando campo com a data\n",
    "df_lop_lists['dateList'] = df_lop_lists['createdAt'].dt.date\n",
    "      #Merge\n",
    "lists_df = df_list_lop\n",
    "lists_df.columns.values[0] = 'listQuestions_id'\n",
    "\n",
    "df_performance = pd.merge(df_performance, lists_df.drop(columns = ['createdAt']), on='listQuestions_id')\n",
    "    #graph1\n",
    "    #Número de alunos na turma\n",
    "    #Media por lista por cada turma\n",
    "newDf = df_performance\n",
    "newDf = newDf.groupby(['user_id', 'class_id'])['medialist'].sum().reset_index()\n",
    "newDf['medialist'] = newDf['medialist'] / lists_df.count().values[0]\n",
    "\n",
    "newDf['aprovado'] = 2\n",
    "for a in range(newDf.count().values[0]):\n",
    "    if newDf['medialist'].values[a]>=50:\n",
    "        newDf['aprovado'][a]=1\n",
    "    else:\n",
    "        newDf['aprovado'][a]=0\n",
    "newDf[newDf['aprovado']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_lop_t = df_class_lop.sort_values('createdAt')\n",
    "classes = df_class_lop_t['class_id'].drop_duplicates().tolist()\n",
    "\n",
    "order_lists = pd.DataFrame(columns = ['class_id', 'listQuestions_id'])\n",
    "for i in range(len(classes)):\n",
    "    one_class = df_class_lop_t[df_class_lop_t['class_id']==classes[i]]\n",
    "    order_lists0 = one_class['listQuestions_id'].drop_duplicates().tolist()\n",
    "    for a in range(len(order_lists0)):\n",
    "        b = dict({'class_id':classes[i], 'listQuestions_id':order_lists0[a]})\n",
    "        order_lists = order_lists.append(b, ignore_index=True)\n",
    "#oberservar a ordem de saída de cada user para não ter problemas posteriores, \n",
    "#por conta da ordem de inserção do 'ateLista' para cada aluno\n",
    "usersp = df_class_lop_t.drop_duplicates(subset=['class_id', 'user_id']).drop(['_id','id','ip','type', 'environment', 'hitPercentage','timeConsuming','createdAt','language', 'answer', 'char_change_number', 'lesson_id','test_id', 'question_id', 'listQuestions_id'], axis=1)\n",
    "usersp['ateLista'] = 0\n",
    "\n",
    "one_class = df_class_lop_t[df_class_lop_t['class_id']==classes[0]]\n",
    "users = one_class['user_id'].drop_duplicates().tolist()\n",
    "\n",
    "alunoPclass = pd.DataFrame(columns = ['class_id', 'qtd_user'])\n",
    "for x in range(len(classes)):\n",
    "    teste = df_class_lop_t[df_class_lop_t['class_id']==classes[x]]\n",
    "    teste = teste['user_id'].drop_duplicates()\n",
    "    teste = teste.count()\n",
    "    b = dict({'class_id':classes[x], 'qtd_user':teste})\n",
    "    alunoPclass = alunoPclass.append(b, ignore_index=True)\n",
    "alunoPclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_ate = []\n",
    "cont = 0\n",
    "a = usersp.columns.tolist()\n",
    "newTeste = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(alunoPclass.count().values[0]):\n",
    "    one_class = df_class_lop_t[df_class_lop_t['class_id']==classes[i]]\n",
    "    users = one_class['user_id'].drop_duplicates().tolist()\n",
    "    for y in range(alunoPclass['qtd_user'][i]):\n",
    "        one_studt = one_class[one_class['user_id']==users[y]]\n",
    "        qtd_ate_l0 = one_studt['listQuestions_id'].drop_duplicates().tolist()\n",
    "        maior = 0\n",
    "        for x in range(len(qtd_ate_l0)):\n",
    "            order_lists1 = order_lists[order_lists['class_id']==classes[i]]\n",
    "            order_lists1 = order_lists1['listQuestions_id'].tolist()\n",
    "            cont=cont+1\n",
    "            for z in range(len(order_lists1)):\n",
    "                if qtd_ate_l0[x] == order_lists1[z]:\n",
    "                    if maior < z:\n",
    "                        maior = z\n",
    "        if(users[y]=='fe3c3b36-a1ab-4365-b088-1686cd5177d0'):\n",
    "            print(maior)\n",
    "            print(cont)\n",
    "        b = dict({'class_id':classes[i], 'user_id':users[y], 'ateLista':maior})\n",
    "        newTeste = newTeste.append(b, ignore_index=True)\n",
    "\n",
    "#usersp['ateLista']=lista_ate\n",
    "\n",
    "#codigo está colocando o 'lista_ate' em uma ordem diferente dos usuarios'\n",
    "#user 'fe3c3b36-a1ab-4365-b088-1686cd5177d0' deveria estar no index 1629\n",
    "#verificar erro // verificar como está a lista de users em 'usersp' e o que corresponde a lista de users de 'lista_ate'\n",
    "\n",
    "#usersp[usersp['user_id']=='fe3c3b36-a1ab-4365-b088-1686cd5177d0']\n",
    "\n",
    "#teste = df_class_lop_t[df_class_lop_t['user_id']=='fe3c3b36-a1ab-4365-b088-1686cd5177d0']\n",
    "#teste = teste['listQuestions_id'].drop_duplicates()\n",
    "#teste\n",
    "\n",
    "#newTeste[newTeste['user_id']=='fe3c3b36-a1ab-4365-b088-1686cd5177d0']\n",
    "usersp = newTeste.copy()\n",
    "usersp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para verificar por turma\n",
    "#qtd_ateLista = usersp.groupby(['ateLista', 'class_id'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "qtd_ateLista = usersp.groupby(['ateLista'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "qtd_ateLista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_totalAteLista = qtd_ateLista\n",
    "for x in range(len(qtd_totalAteLista)):\n",
    "    qtd_totalAteLista['totalDeAlunosAteLista'][x+1]= qtd_totalAteLista['totalDeAlunosAteLista'][x] + qtd_totalAteLista['totalDeAlunosAteLista'][x+1]\n",
    "    if x==len(qtd_totalAteLista)-2:\n",
    "        break\n",
    "qtd_totalAteLista\n",
    "#apagar ultima linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erro\n",
    "usersAteApr = pd.merge(newDf,usersp, on=['user_id', 'class_id'], how='outer')\n",
    "usersAteApr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erro\n",
    "aprovs = usersAteApr[usersAteApr['aprovado']==1]\n",
    "aprAlista = aprovs.groupby(['ateLista'])['aprovado'].count().reset_index(name='totalDeAprAteLista')\n",
    "aprAlista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ate_Lista = usersp.groupby(['ateLista'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "porcentAtePlista = usersp.groupby(['ateLista'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "porcentAtePlista['totalDeAlunosAteLista']=0.0\n",
    "for x in range(len(ate_Lista)):\n",
    "    for a in range(len(aprAlista)):\n",
    "        if ate_Lista['ateLista'][x] == aprAlista['ateLista'][a]:\n",
    "            porcentAtePlista['totalDeAlunosAteLista'][x] = aprAlista['totalDeAprAteLista'][a] / ate_Lista['totalDeAlunosAteLista'][x]\n",
    "porcentAtePlista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvando todas as submissoes em ordem temporal\n",
    "df_class_lop_t = df_class_lop.sort_values('createdAt')\n",
    "#salavndo a quantidade de listas que cada aluno resolveu\n",
    "usersQtd = df_class_lop_t.groupby(['user_id','listQuestions_id', 'class_id'])['question_id'].count().reset_index(name='qtdLista')\n",
    "usersQtd = usersQtd.groupby(['user_id', 'class_id'])['listQuestions_id'].count().reset_index(name='qtdLista')\n",
    "\n",
    "usersQtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_Lista = usersQtd.groupby(['qtdLista'])['user_id'].count().reset_index(name='totalDeAlunosQtdLista')\n",
    "qtd_Lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porc_qtd_Lista = usersQtd.groupby(['qtdLista'])['user_id'].count().reset_index(name='totalDeAlunosQtdLista')\n",
    "for a in range(len(qtd_Lista)):\n",
    "    atual = usersQtd[usersQtd['qtdLista']==a+1]\n",
    "    cont=0\n",
    "    total=atual.count().values[0]\n",
    "    for x in range(total):\n",
    "        verif_user=newDf[newDf['user_id']==atual['user_id'].iloc[x]]\n",
    "        if verif_user['aprovado'].values[0]==1:\n",
    "            cont=cont+1\n",
    "#    porc_qtd_Lista['totalDeAlunosQtdLista'][a]= (cont/total)\n",
    "#    print(total)\n",
    "#    if a==len(qtd_totalAteLista)-1:\n",
    "#        break\n",
    "#atual = usersQtd[usersQtd['qtdLista']==15]\n",
    "#total=atual.count().values[0]\n",
    "#verif_user=aprovados1[aprovados1['user_id']==atual['user_id'].iloc[0]]\n",
    "#aprov = verif_user['aprovado'].values[0]\n",
    "#porc_qtd_Lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersQtdApr = pd.merge(newDf,usersQtd, on=['user_id', 'class_id'], how='outer')\n",
    "usersQtdApr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprovs = usersQtdApr[usersQtdApr['aprovado']==1]\n",
    "aprPlista = aprovs.groupby(['qtdLista'])['aprovado'].count().reset_index(name='totalDeAprQtdLista')\n",
    "aprPlista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_Lista = usersQtd.groupby(['qtdLista'])['user_id'].count().reset_index(name='totalDeAlunosQtdLista')\n",
    "porcentAprPlista = usersQtd.groupby(['qtdLista'])['user_id'].count().reset_index(name='totalDeAlunosQtdLista')\n",
    "porcentAprPlista['totalDeAlunosQtdLista']=0.0\n",
    "for x in range(len(qtd_Lista)):\n",
    "    for a in range(len(aprPlista)):\n",
    "        if qtd_Lista['qtdLista'][x] == aprPlista['qtdLista'][a]:\n",
    "#            print(x)\n",
    "            porcentAprPlista['totalDeAlunosQtdLista'][x] = aprPlista['totalDeAprQtdLista'][a] / qtd_Lista['totalDeAlunosQtdLista'][x]\n",
    "#c = aprPlista['totalDeAprQtdLista'][2] / qtd_Lista['totalDeAlunosQtdLista'][13]\n",
    "#c\n",
    "porcentAprPlista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_ateLista = usersp.groupby(['ateLista'])['user_id'].count().reset_index(name='totalDeAlunosAteLista')\n",
    "\n",
    "usersQtdApr2 = pd.merge(newDf,usersp, on=['user_id','class_id'], how='outer')\n",
    "usersQtdApr2\n",
    "#como user 'fe3c3b36-a1ab-4365-b088-1686cd5177d0' foi aprovado, fazendo somente ate a lista 7 e nao constando na\n",
    "#lista de quem foi aprovado com ate 7 listas feitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_ate = pd.merge(usersQtd,usersp, on=['user_id','class_id'], how='outer')\n",
    "usersQtdAte = pd.merge(newDf,qtd_ate, on=['user_id','class_id'], how='outer')\n",
    "usersQtdAte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentAtePlista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contando o erro por questao acima do tempo zero para prevenir duplo clicke. geralmente, se há cola ou algum problema relacionado, acaba nao sendo um erro na questao\n",
    "#buscando erros por lista, por aluno\n",
    "df_class_lop_t['timeInSecounds'] = df_class_lop_t['timeConsuming'].divide(1000).astype(int)\n",
    "\n",
    "df_without_duplicates = df_class_lop_t[df_class_lop_t[\"timeInSecounds\"] > 0].drop(['language','test_id','environment','timeConsuming','createdAt','timeInSecounds','char_change_number', 'ip', 'type', 'answer', 'lesson_id', 'id'], axis=1)\n",
    "df_erro = df_without_duplicates[df_without_duplicates[\"hitPercentage\"] == 0]\n",
    "df_erro = df_erro.groupby(['user_id','class_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalError')\n",
    "df_erro = df_erro.groupby(['class_id','user_id'])['totalError'].sum()\n",
    "\n",
    "#buscando quantidade de questoes certas por lista por aluno\n",
    "df_acerto = df_without_duplicates[df_without_duplicates[\"hitPercentage\"] > 0]\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalAcert')\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id'])['totalAcert'].sum()\n",
    "\n",
    "#buscando quantidade de questoes que com 100% de acerto por lista por aluno\n",
    "df_100 = df_without_duplicates[df_without_duplicates[\"hitPercentage\"] == 100].drop_duplicates()\n",
    "df_100 = df_100.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='acert_100')\n",
    "df_100 = df_100.groupby(['class_id','user_id'])['acert_100'].sum()\n",
    "\n",
    "#buscar se o aluno chegou a tirar 100 na questão ou a nota final.\n",
    "#há mais de um acerto, pois há mais vezes que tentam tirar mais que zero, mas nem sempre chegam no 100\n",
    "#avaliar a possibilidade de colocar a nota maxima do aluno em coluna\n",
    "\n",
    "df = pd.merge(df_erro, df_acerto, on=['class_id','user_id'], how='outer')\n",
    "df = pd.merge(df, df_100, on=['class_id','user_id'], how='outer')\n",
    "df.replace(np.NaN, 0, inplace = True)\n",
    "df = pd.merge(df, newDf, on=['class_id','user_id']).drop('medialist', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_without_duplicates.drop(['_id', 'hitPercentage', 'listQuestions_id'], axis=1).drop_duplicates()\n",
    "qtd_qPa = a.groupby(['class_id','user_id'])['question_id'].count().reset_index(name='totalQuest')\n",
    "media_df = pd.merge(df, qtd_qPa, on=['class_id','user_id'])\n",
    "media_df['totalError'] = media_df['totalError'] / media_df['totalQuest']\n",
    "media_df['totalAcert'] = media_df['totalAcert'] / media_df['totalQuest']\n",
    "media_df['acert_100'] = media_df['acert_100'] / media_df['totalQuest']\n",
    "media_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_subm = df_without_duplicates.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='total_subm')\n",
    "df_cont_subm = df_cont_subm.groupby(['class_id','user_id'])['total_subm'].sum()\n",
    "media_df1 = pd.merge(df_cont_subm, qtd_qPa, on=['class_id','user_id'])\n",
    "media_df1['total_subm'] = media_df1['total_subm'] / media_df1['totalQuest']\n",
    "media_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.merge(df_cont_subm, df, on=['class_id','user_id'])\n",
    "prob_total = pd.merge(df_cont_subm, df, on=['class_id','user_id'])\n",
    "prob_total['totalError'] = prob_total['totalError'] / prob_total['total_subm']\n",
    "prob_total['totalAcert'] = prob_total['totalAcert'] / prob_total['total_subm']\n",
    "prob_total['acert_100'] = prob_total['acert_100'] / prob_total['total_subm']\n",
    "prob_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refazer o indice de desistencia, tendo em vista os índices já vistos \n",
    "des = usersp.copy()\n",
    "des['desistente'] = 2\n",
    "for a in range(des.count().values[0]):\n",
    "    if des['ateLista'].values[a]<4:\n",
    "        des['desistente'][a]=1\n",
    "    else:\n",
    "        des['desistente'][a]=0\n",
    "des[des['desistente']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_total_des = pd.merge(des, prob_total, on=['class_id','user_id']).drop('aprovado', axis=1)\n",
    "prob_total_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_subm = df_without_duplicates.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='total_subm')\n",
    "df_cont_subm = df_cont_subm.groupby(['class_id','user_id'])['total_subm'].sum()\n",
    "\n",
    "a = df_without_duplicates.drop(['_id', 'hitPercentage', 'listQuestions_id'], axis=1).drop_duplicates()\n",
    "qtd_qPa = a.groupby(['class_id','user_id'])['question_id'].count().reset_index(name='totalQuest')\n",
    "\n",
    "media_des0 = pd.merge(df_cont_subm, qtd_qPa, on=['class_id','user_id'])\n",
    "media_des0['subm/quest'] = media_des0['total_subm'] / media_des0['totalQuest']\n",
    "media_des = pd.merge(media_des0, des, on=['class_id','user_id'])\n",
    "media_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob_total_des\n",
    "ind = prob_total_des.copy()\n",
    "ind = ind.drop(['ateLista', 'total_subm'], axis=1)\n",
    "ind = pd.merge(ind, media_des0, on=['class_id', 'user_id'])\n",
    "ind['teste'] = ind['subm/quest'] * ind['totalAcert']\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_des = ind[ind['desistente']==1]\n",
    "test_ndes = ind[ind['desistente']==0]\n",
    "\n",
    "newind = ind[ind['teste']<=test_des['teste'].max()]\n",
    "newind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newind['teste2'] = ind['teste'] * ind['acert_100']\n",
    "newind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_lop_t['timeInSecounds'] = df_class_lop_t['timeConsuming'].divide(1000).astype(int)\n",
    "df_without_duplicates = df_class_lop_t[df_class_lop_t[\"timeInSecounds\"] > 0].drop(['language','test_id','environment','timeConsuming','char_change_number', 'ip', 'type', 'answer', 'lesson_id', 'id'], axis=1)\n",
    "\n",
    "a = df_without_duplicates.columns.tolist()\n",
    "list1 = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(alunoPclass.count().values[0]):\n",
    "    one_class = df_without_duplicates[df_without_duplicates['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists[order_lists['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists1['listQuestions_id'].tolist()\n",
    "    order_lists1 = order_lists1[0]\n",
    "    listeste = one_class[one_class['listQuestions_id']==order_lists1]\n",
    "    list1 = list1.append(listeste, ignore_index=True)\n",
    "\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_aqui = des.copy()\n",
    "\n",
    "for a in range(des_aqui.count().values[0]):\n",
    "    if des_aqui['ateLista'].values[a]<1:\n",
    "        des_aqui['desistente'][a]=1\n",
    "    else:\n",
    "        des_aqui['desistente'][a]=0\n",
    "\n",
    "df_erro = list1[list1[\"hitPercentage\"] == 0]\n",
    "df_erro = df_erro.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalError')\n",
    "df_erro = df_erro.groupby(['class_id','user_id'])['totalError'].sum()\n",
    "\n",
    "#buscando quantidade de questoes certas por lista por aluno\n",
    "df_acerto = list1[list1[\"hitPercentage\"] > 0]\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalAcert')\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id'])['totalAcert'].sum()\n",
    "\n",
    "#buscando quantidade de questoes que com 100% de acerto por lista por aluno\n",
    "df_100 = list1[list1[\"hitPercentage\"] == 100].drop_duplicates()\n",
    "df_100 = df_100.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='acert_100')\n",
    "df_100 = df_100.groupby(['class_id','user_id'])['acert_100'].sum()\n",
    "\n",
    "df_cont_subm = list1.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='total_subm')\n",
    "df_cont_subm = df_cont_subm.groupby(['class_id','user_id'])['total_subm'].sum()\n",
    "\n",
    "a = list1.drop(['_id', 'hitPercentage', 'listQuestions_id','createdAt', 'timeInSecounds'], axis=1).drop_duplicates()\n",
    "qtd_qPa = a.groupby(['class_id','user_id'])['question_id'].count().reset_index(name='totalQuest')\n",
    "\n",
    "media_list1 = pd.merge(df_cont_subm, qtd_qPa, on=['class_id','user_id'])\n",
    "media_list1['subm/quest'] = media_list1['total_subm'] / media_list1['totalQuest']\n",
    "\n",
    "tempott = list1.groupby(['class_id','user_id'])['timeInSecounds'].sum()\n",
    "\n",
    "#buscar se o aluno chegou a tirar 100 na questão ou a nota final.\n",
    "#há mais de um acerto, pois há mais vezes que tentam tirar mais que zero, mas nem sempre chegam no 100\n",
    "#avaliar a possibilidade de colocar a nota maxima do aluno em coluna\n",
    "\n",
    "df_list1 = pd.merge(df_erro, df_acerto, on=['class_id','user_id'], how='outer')\n",
    "df_list1 = pd.merge(df_list1, df_100, on=['class_id','user_id'], how='outer')\n",
    "df_list1.replace(np.NaN, 0, inplace = True)\n",
    "df_list1 = pd.merge(df_list1, des_aqui, on=['class_id','user_id'])\n",
    "df_list1 = pd.merge(df_list1, media_list1, on=['class_id','user_id'])\n",
    "df_list1 = pd.merge(df_list1, tempott, on=['class_id','user_id'])\n",
    "#des_aqui[des_aqui['desistente']==1]\n",
    "#print(des_aqui[des_aqui['desistente']==1].count().values[0])\n",
    "df_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list1[df_list1['desistente']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list1['teste'] = df_list1['acert_100'] * df_list1['subm/quest']\n",
    "grap1 = df_list1[df_list1['teste']>0]\n",
    "plt.scatter(grap1['teste'].tolist(), \n",
    "            grap1['desistente'].tolist(), \n",
    "            marker='o')\n",
    "plt.show()\n",
    "print(grap1['teste'].min())\n",
    "print(grap1['teste'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grap = grap1[grap1['desistente']==1]\n",
    "#test_ndes = ind[ind['desistente']==0]\n",
    "\n",
    "teste1 = grap1[grap1['teste']<=grap['teste'].max()]\n",
    "print(teste1.count().values[0])\n",
    "#teste1[teste1['desistente']==1]\n",
    "#teste1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_list1['totalError'] = df_list1['totalError'] / df_list1['total_subm']\n",
    "df_list1['totalAcert'] = df_list1['totalAcert'] / df_list1['total_subm']\n",
    "df_list1['acert_100'] = df_list1['acert_100'] / df_list1['total_subm']\n",
    "df_list1[df_list1['desistente']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t = df_list1[df_list1['totalError']>= 0.55]\n",
    "# t = t[t['teste']<=27]\n",
    "# t = t[t['teste']>=8.5]\n",
    "# t = t[t['totalQuest']<=5]\n",
    "# t = t[t['subm/quest']<=9]\n",
    "# t\n",
    "\n",
    "t = df_list1[df_list1['totalError']>= 0.66]\n",
    "t = t[t['totalError']<= 0.885]\n",
    "#    #t = df_list1[df_list1['totalError']>= 0.57]\n",
    "t = t[t['teste']<=27]\n",
    "#    #t = t[t['teste']<=7.5]\n",
    "t = t[t['teste']>=8.5]\n",
    "t = t[t['totalQuest']<=5]\n",
    "t = t[t['totalQuest']>=2]\n",
    "t = t[t['subm/quest']<=6.4]\n",
    "#    #t = t[t['subm/quest']<=9]\n",
    "t = t[t['total_subm']>=7]\n",
    "t = t[t['total_subm']<=30]\n",
    "t = t[t['timeInSecounds']>=1967]\n",
    "t = t[t['timeInSecounds']<=14994]\n",
    "print(t.count().values[0])\n",
    "t\n",
    "\n",
    "\n",
    "#podendo ver a quantidade de alunos que pode desistir futuramente\n",
    "#oberservar quantos, nessa metrica, foram aprovados\n",
    "#oberservar quais mais podem desistir nessa, quais mais podem desistir nas próximas listas\n",
    "#oberservar quais mais devem ter cuidados durante o segmento das questoes\n",
    "#obervar ate quantos % de media de erro por submissao pode haver uma reprovação e quantos % acima desses os alunos erram e seguem\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.groupby(['ateLista'])['user_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nt = df_list1[df_list1['acert_100']>= 0.117]\n",
    "nt['teste'] = nt['teste'] * nt['acert_100']\n",
    "nt[nt['desistente']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = nt[nt['acert_100']<= 0.3572]\n",
    "nt = nt[nt['acert_100']>= 0.117]\n",
    "#    #t = df_list1[df_list1['totalError']>= 0.57]\n",
    "nt = nt[nt['teste']<=7.2]\n",
    "#    #t = t[t['teste']<=7.5]\n",
    "nt = nt[nt['teste']>=1]\n",
    "nt = nt[nt['totalQuest']<=5]\n",
    "nt = nt[nt['totalQuest']>=2]\n",
    "nt = nt[nt['subm/quest']<=6]\n",
    "nt = nt[nt['subm/quest']>=2.25]\n",
    "#    #t = t[t['subm/quest']<=9]\n",
    "nt = nt[nt['total_subm']>=9]\n",
    "nt = nt[nt['total_subm']<=24]\n",
    "nt = nt[nt['timeInSecounds']>=2343]\n",
    "nt = nt[nt['timeInSecounds']<=14175]\n",
    "print(nt.count().values[0])\n",
    "nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nt.groupby(['ateLista'])['user_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_lop_t['timeInSecounds'] = df_class_lop_t['timeConsuming'].divide(1000).astype(int)\n",
    "df_without_duplicates = df_class_lop_t[df_class_lop_t[\"timeInSecounds\"] > 0].drop(['language','test_id','environment','timeConsuming','char_change_number', 'ip', 'type', 'answer', 'lesson_id', 'id'], axis=1)\n",
    "\n",
    "a = df_without_duplicates.columns.tolist()\n",
    "list2 = pd.DataFrame(columns = a)\n",
    "\n",
    "for i in range(alunoPclass.count().values[0]):\n",
    "    one_class = df_without_duplicates[df_without_duplicates['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists[order_lists['class_id']==classes[i]]\n",
    "    order_lists1 = order_lists1['listQuestions_id'].tolist()\n",
    "    order_lists1 = order_lists1[1]\n",
    "    listeste = one_class[one_class['listQuestions_id']==order_lists1]\n",
    "    list2 = list2.append(listeste, ignore_index=True)\n",
    "list2['user_id'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_aqui = des.copy()\n",
    "\n",
    "tlist2 = list1.copy()\n",
    "tlist2 = tlist2.append(list2)\n",
    "tlist2 = tlist2.reset_index()\n",
    "\n",
    "a = des_aqui[ des_aqui['ateLista'] < 1]\n",
    "indexNames = []\n",
    "for i in a.values:\n",
    "    b = tlist2[tlist2['user_id'] == i[0]].index\n",
    "    for x in b:\n",
    "        indexNames.append(x)\n",
    "tlist2 = tlist2.drop(tlist2.index[indexNames])\n",
    "\n",
    "for a in range(des_aqui.count().values[0]):\n",
    "    if des_aqui['ateLista'].values[a]<2:\n",
    "        des_aqui['desistente'][a]=1\n",
    "    else:\n",
    "        des_aqui['desistente'][a]=0\n",
    "        \n",
    "a = des[ des['ateLista'] < 1]\n",
    "indexNames = []\n",
    "for i in a.values:\n",
    "    b = des_aqui[des_aqui['user_id'] == i[0]].index\n",
    "    for x in b:\n",
    "        indexNames.append(x)\n",
    "des_aqui = des_aqui.drop(des_aqui.index[indexNames])\n",
    "\n",
    "list2 = tlist2.copy()\n",
    "\n",
    "df_erro = list2[list2[\"hitPercentage\"] == 0]\n",
    "df_erro = df_erro.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalError')\n",
    "df_erro = df_erro.groupby(['class_id','user_id'])['totalError'].sum()\n",
    "\n",
    "#buscando quantidade de questoes certas por lista por aluno\n",
    "df_acerto = list2[list2[\"hitPercentage\"] > 0]\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='totalAcert')\n",
    "df_acerto = df_acerto.groupby(['class_id','user_id'])['totalAcert'].sum()\n",
    "\n",
    "#buscando quantidade de questoes que com 100% de acerto por lista por aluno\n",
    "df_100 = list2[list2[\"hitPercentage\"] == 100].drop_duplicates()\n",
    "df_100 = df_100.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='acert_100')\n",
    "df_100 = df_100.groupby(['class_id','user_id'])['acert_100'].sum()\n",
    "\n",
    "df_cont_subm = list2.groupby(['class_id','user_id','listQuestions_id','question_id'])['hitPercentage'].count().reset_index(name='total_subm')\n",
    "df_cont_subm = df_cont_subm.groupby(['class_id','user_id'])['total_subm'].sum()\n",
    "\n",
    "a = list2.drop(['_id', 'hitPercentage', 'listQuestions_id','createdAt', 'timeInSecounds'], axis=1)\n",
    "a = a.drop('index', axis=1)\n",
    "a = a.drop_duplicates()\n",
    "qtd_qPa = a.groupby(['class_id','user_id'])['question_id'].count().reset_index(name='totalQuest')\n",
    "\n",
    "media_list1 = pd.merge(df_cont_subm, qtd_qPa, on=['class_id','user_id'])\n",
    "media_list1['subm/quest'] = media_list1['total_subm'] / media_list1['totalQuest']\n",
    "\n",
    "tempott = list2.groupby(['class_id','user_id'])['timeInSecounds'].sum()\n",
    "\n",
    "#buscar se o aluno chegou a tirar 100 na questão ou a nota final.\n",
    "#há mais de um acerto, pois há mais vezes que tentam tirar mais que zero, mas nem sempre chegam no 100\n",
    "#avaliar a possibilidade de colocar a nota maxima do aluno em coluna\n",
    "\n",
    "df_list2 = pd.merge(df_erro, df_acerto, on=['class_id','user_id'], how='outer')\n",
    "df_list2 = pd.merge(df_list2, df_100, on=['class_id','user_id'], how='outer')\n",
    "df_list2.replace(np.NaN, 0, inplace = True)\n",
    "df_list2 = pd.merge(df_list2, des_aqui, on=['class_id','user_id'])\n",
    "df_list2 = pd.merge(df_list2, media_list1, on=['class_id','user_id'])\n",
    "df_list2 = pd.merge(df_list2, tempott, on=['class_id','user_id'])\n",
    "#des_aqui[des_aqui['desistente']==1]\n",
    "#print(des_aqui[des_aqui['desistente']==1].count().values[0])\n",
    "df_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list2['percTotalError'] = df_list2['totalError'] / df_list2['total_subm']\n",
    "df_list2['percTotalAcert'] = df_list2['totalAcert'] / df_list2['total_subm']\n",
    "df_list2['percAcert_100'] = df_list2['acert_100'] / df_list2['total_subm']\n",
    "df_list2[df_list2['desistente']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_desist = df_list2['desistente'].tolist()\n",
    "x_dados = df_list2.drop(['class_id', 'user_id', 'desistente', 'ateLista'], axis=1)\n",
    "x_dados = x_dados.values\n",
    "x_dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_dados, y_desist, test_size=0.3, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=1)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = df_list2.drop(['class_id', 'user_id', 'desistente', 'ateLista'], axis=1)\n",
    "bx = bx.columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 14))\n",
    "\n",
    "plot_tree(dt_model, filled=True, rounded=True,class_names=['Não desistente','Desistente',],feature_names=bx)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
